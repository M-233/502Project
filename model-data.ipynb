{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Predictive Model(s)\n",
    "\n",
    "In this workbook, you will read the merged dataset you created previously and you will create transformer, estimators and pipelines to build a binary classification model to predict wether a trip has a tip or not.\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "1. Read in your merged dataset\n",
    "2. Use transformes and encoders to perform feature engineering\n",
    "3. Split into training and testing\n",
    "4. Build `LogisticRegression` model(s) and train them using pipelines\n",
    "5. Evaluate the performance of the model(s) using `BinaryClassificationMetrics`\n",
    "\n",
    "You are welcome to add as many cells as you need below up until the next section. **You must include comments in your code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"HW-4\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-20-99.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>HW-4</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ffa80819be0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "sc    = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-20-99.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>HW-5</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=HW-5>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.ml import Pipeline, Model\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorIndexer\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.ml.feature import RFormula\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyctaxi = spark.read.parquet(\"s3://502hw4/merged_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- medallion: string (nullable = true)\n",
      " |-- hack_license: string (nullable = true)\n",
      " |-- vendor_id: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- fare_amount: float (nullable = true)\n",
      " |-- surcharge: float (nullable = true)\n",
      " |-- mta_tax: float (nullable = true)\n",
      " |-- tip_amount: float (nullable = true)\n",
      " |-- tolls_amount: float (nullable = true)\n",
      " |-- total_amount: float (nullable = true)\n",
      " |-- rate_code: string (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_time_in_secs: integer (nullable = true)\n",
      " |-- trip_distance: float (nullable = true)\n",
      " |-- pickup_longitude: float (nullable = true)\n",
      " |-- pickup_latitude: float (nullable = true)\n",
      " |-- dropoff_longitude: float (nullable = true)\n",
      " |-- dropoff_latitude: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nyctaxi.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If tipped 1, otherwise 0\n",
    "nyctaxi=nyctaxi.withColumn(\"tipped\", when(nyctaxi[\"tip_amount\"]>0.0, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create other variables\n",
    "nyctaxi=nyctaxi.withColumn(\"pickup_hour\", hour(col(\"pickup_datetime\")))\n",
    "nyctaxi=nyctaxi.withColumn(\"weekday\", date_format(\"pickup_datetime\",'EEEE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyctaxi.createOrReplaceTempView(\"nyctaxi_table\")\n",
    "nyctaxi = spark.sql(\"\"\"SELECT *,\n",
    "CASE WHEN pickup_hour <= 6 OR pickup_hour >= 20 THEN 'night'\n",
    "     WHEN pickup_hour >= 7 AND pickup_hour <= 10 THEN 'am_rush'\n",
    "     WHEN pickup_hour >= 11 AND pickup_hour <= 15 THEN 'afternoon'\n",
    "     ELSE 'pm_rush' END AS time_bins\n",
    "FROM nyctaxi_table\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_vendor = StringIndexer(inputCol=\"vendor_id\", outputCol=\"vendor_X\")\n",
    "string_rate = StringIndexer(inputCol=\"rate_code\", outputCol=\"rate_X\")\n",
    "string_payment = StringIndexer(inputCol=\"payment_type\", outputCol=\"payment_X\")\n",
    "string_time = StringIndexer(inputCol=\"time_bins\", outputCol=\"time_bins_X\")\n",
    "\n",
    "encoder_vendor = OneHotEncoder(inputCol=\"vendor_X\", outputCol=\"vendor_vec\", dropLast=False)\n",
    "encoder_rate = OneHotEncoder(inputCol=\"rate_X\", outputCol=\"rate_vec\", dropLast=False)\n",
    "encoder_payment = OneHotEncoder(inputCol=\"payment_X\", outputCol=\"payment_vec\", dropLast=False)\n",
    "encoder_time = OneHotEncoder(inputCol=\"time_bins_X\", outputCol=\"time_bins_vec\", dropLast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_final = Pipeline(stages=[string_vendor, encoder_vendor, string_rate, encoder_rate, \n",
    "                             string_payment, encoder_payment, string_time, encoder_time\n",
    "                            ]).fit(nyctaxi).transform(nyctaxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+-------------------+------------+-----------+---------+-------+----------+------------+------------+---------+------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------+-----------+--------+---------+--------+-------------+------+--------------+---------+-------------+-----------+-------------+\n",
      "|           medallion|        hack_license|vendor_id|    pickup_datetime|payment_type|fare_amount|surcharge|mta_tax|tip_amount|tolls_amount|total_amount|rate_code|store_and_fwd_flag|   dropoff_datetime|passenger_count|trip_time_in_secs|trip_distance|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|tipped|pickup_hour| weekday|time_bins|vendor_X|   vendor_vec|rate_X|      rate_vec|payment_X|  payment_vec|time_bins_X|time_bins_vec|\n",
      "+--------------------+--------------------+---------+-------------------+------------+-----------+---------+-------+----------+------------+------------+---------+------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------+-----------+--------+---------+--------+-------------+------+--------------+---------+-------------+-----------+-------------+\n",
      "|00005007A9F30E289...|0938A8DBC34197F8F...|      CMT|2013-09-08 11:01:39|         CRD|        7.0|      0.0|    0.5|       1.5|         0.0|         9.0|        1|                 N|2013-09-08 11:07:55|              1|              375|          1.4|       -73.95424|      40.773064|          -73.972|        40.76556|     1|         11|  Sunday|afternoon|     0.0|(2,[0],[1.0])|   0.0|(26,[0],[1.0])|      0.0|(5,[0],[1.0])|        1.0|(4,[1],[1.0])|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-09-30 08:18:49|         CRD|        6.0|      0.0|    0.5|       1.3|         0.0|         7.8|        1|                 N|2013-09-30 08:25:29|              2|              399|          0.7|        -73.9709|       40.79809|         -73.9694|       40.790306|     1|          8|  Monday|  am_rush|     0.0|(2,[0],[1.0])|   0.0|(26,[0],[1.0])|      0.0|(5,[0],[1.0])|        3.0|(4,[3],[1.0])|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-09-30 12:36:25|         CSH|        8.5|      0.0|    0.5|       0.0|         0.0|         9.0|        1|                 N|2013-09-30 12:45:29|              1|              543|          2.0|       -74.00138|      40.716274|       -74.003296|       40.739227|     0|         12|  Monday|afternoon|     0.0|(2,[0],[1.0])|   0.0|(26,[0],[1.0])|      1.0|(5,[1],[1.0])|        1.0|(4,[1],[1.0])|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-10-11 09:43:34|         CRD|        5.5|      0.0|    0.5|       1.0|         0.0|         7.0|        1|                 N|2013-10-11 09:49:27|              1|              353|          0.5|       -73.97774|        40.7367|        -73.98601|       40.740173|     1|          9|  Friday|  am_rush|     0.0|(2,[0],[1.0])|   0.0|(26,[0],[1.0])|      0.0|(5,[0],[1.0])|        3.0|(4,[3],[1.0])|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-10-19 11:35:43|         CSH|       22.0|      0.0|    0.5|       0.0|         0.0|        22.5|        1|                 N|2013-10-19 12:06:41|              2|             1857|          4.9|       -73.95034|      40.779564|        -74.00521|        40.74007|     0|         11|Saturday|afternoon|     0.0|(2,[0],[1.0])|   0.0|(26,[0],[1.0])|      1.0|(5,[1],[1.0])|        1.0|(4,[1],[1.0])|\n",
      "+--------------------+--------------------+---------+-------------------+------------+-----------+---------+-------+----------+------------+------------+---------+------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------+-----------+--------+---------+--------+-------------+------+--------------+---------+-------------+-----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nyc_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training records: 138553269\n",
      "Number of testing records : 34631822\n"
     ]
    }
   ],
   "source": [
    "splitted_data = nyc_final.randomSplit([0.8, 0.2], 24)\n",
    "train_data = splitted_data[0]\n",
    "test_data = splitted_data[1]\n",
    "\n",
    "print(\"Number of training records: \" + str(train_data.count()))\n",
    "print(\"Number of testing records : \" + str(test_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[medallion: string, hack_license: string, vendor_id: string, pickup_datetime: timestamp, payment_type: string, fare_amount: float, surcharge: float, mta_tax: float, tip_amount: float, tolls_amount: float, total_amount: float, rate_code: string, store_and_fwd_flag: string, dropoff_datetime: timestamp, passenger_count: int, trip_time_in_secs: int, trip_distance: float, pickup_longitude: float, pickup_latitude: float, dropoff_longitude: float, dropoff_latitude: float, tipped: int, pickup_hour: int, weekday: string, time_bins: string, vendor_X: double, vendor_vec: vector, rate_X: double, rate_vec: vector, payment_X: double, payment_vec: vector, time_bins_X: double, time_bins_vec: vector]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.cache()\n",
    "test_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LogisticRegression model\n",
    "log_reg = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pickup_hour, Passenger count, Trip time, Trip distance\n",
    "# Fare amount, Vendor id, Payment type, Rate code, Time bins\n",
    "class_formula = RFormula(formula=\"tipped ~ pickup_hour + passenger_count + trip_time_in_secs + trip_distance + fare_amount + vendor_X + rate_X + payment_X + time_bins_X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(stages=[class_formula, log_reg]).fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the prediction results into rdd\n",
    "predictions_and_labels = predictions['label', 'prediction'].rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build metrics on the rdd \n",
    "metrics = BinaryClassificationMetrics(predictions_and_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the following cells, please provide the requested code and output. Do not change the order and/or structure of the cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, print the Area Under the Curve (AUC) for your binary classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 0.9832600564501338\n"
     ]
    }
   ],
   "source": [
    "print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, provide the code that saves your model your S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to S3\n",
    "model.save(\"s3://502hw4/hw4_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
